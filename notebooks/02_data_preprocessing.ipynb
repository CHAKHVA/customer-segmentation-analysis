{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "**Author:** Nino Gagnidze  \n",
    "**Date:** 2026-01-11  \n",
    "**Purpose:** Clean and preprocess the Mall Customers dataset for analysis and modeling\n",
    "\n",
    "## Objectives\n",
    "- Handle missing values and duplicates\n",
    "- Detect and handle outliers\n",
    "- Create derived features (age groups, income categories, spending categories)\n",
    "- Encode categorical variables\n",
    "- Save processed data for downstream analysis\n",
    "\n",
    "## Preprocessing Decisions\n",
    "Based on the data exploration notebook:\n",
    "- Missing values: To be handled if any exist\n",
    "- Duplicates: To be removed\n",
    "- Outliers: To be kept (they represent valid customer segments)\n",
    "- Feature engineering: Create categorical groupings for better analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import custom preprocessing functions\n",
    "from data_processing import (\n",
    "    load_raw_data,\n",
    "    check_missing_values,\n",
    "    handle_missing_values,\n",
    "    remove_duplicates,\n",
    "    detect_outliers_iqr,\n",
    "    handle_outliers,\n",
    "    create_age_groups,\n",
    "    create_income_categories,\n",
    "    create_spending_categories,\n",
    "    encode_categorical_features,\n",
    "    preprocess_pipeline,\n",
    "    save_processed_data,\n",
    "    generate_preprocessing_report\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw dataset\n",
    "raw_data_path = '../data/raw/mall_customers.csv'\n",
    "df_original = load_raw_data(raw_data_path)\n",
    "\n",
    "print(f\"\\nOriginal dataset shape: {df_original.shape}\")\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Summary:\")\n",
    "missing_summary = check_missing_values(df_original)\n",
    "\n",
    "if len(missing_summary) == 0:\n",
    "    print(\"No missing values found.\")\n",
    "else:\n",
    "    print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicate_count = df_original.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze outliers for each numerical feature\n",
    "numerical_features = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n",
    "\n",
    "print(\"Outlier Analysis (IQR Method):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "outlier_summary = {}\n",
    "\n",
    "for feature in numerical_features:\n",
    "    outliers, stats = detect_outliers_iqr(df_original, feature)\n",
    "    outlier_summary[feature] = stats\n",
    "    \n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(f\"  Lower Bound: {stats['lower_bound']:.2f}\")\n",
    "    print(f\"  Upper Bound: {stats['upper_bound']:.2f}\")\n",
    "    print(f\"  Outlier Count: {stats['outlier_count']}\")\n",
    "    print(f\"  Outlier Percentage: {stats['outlier_percentage']:.2f}%\")\n",
    "    \n",
    "    if stats['outlier_count'] > 0:\n",
    "        print(f\"  Outlier values: {sorted(outliers[feature].tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing Decision: Outlier Handling\n",
    "\n",
    "**Decision:** Keep outliers\n",
    "\n",
    "**Justification:**\n",
    "In customer segmentation, outliers often represent valid and important customer segments (e.g., high-income high-spenders or low-income low-spenders). These are real customers with distinct behaviors that should be included in our analysis and clustering. Removing them would:\n",
    "1. Reduce the diversity of customer segments identified\n",
    "2. Potentially miss important business insights\n",
    "3. Decrease the practical applicability of the model\n",
    "\n",
    "Therefore, we will keep all outliers in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Apply Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply complete preprocessing pipeline\n",
    "df_processed = preprocess_pipeline(\n",
    "    df_original,\n",
    "    handle_missing=True,\n",
    "    remove_duplicates_flag=True,\n",
    "    handle_outliers_flag=False,  # Keep outliers\n",
    "    outlier_method='keep',\n",
    "    create_features=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verify Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display processed data info\n",
    "print(\"Processed Data Information:\")\n",
    "print(\"=\" * 80)\n",
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of processed data\n",
    "print(\"First 10 rows of processed data:\")\n",
    "df_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new features\n",
    "print(\"New Features Created:\")\n",
    "new_features = [col for col in df_processed.columns if col not in df_original.columns]\n",
    "print(new_features)\n",
    "\n",
    "print(\"\\nSample of new features:\")\n",
    "df_processed[new_features].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Age Groups distribution\n",
    "print(\"Age Group Distribution:\")\n",
    "print(df_processed['Age_Group'].value_counts().sort_index())\n",
    "print(\"\\nPercentage:\")\n",
    "print((df_processed['Age_Group'].value_counts(normalize=True) * 100).sort_index().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Income Categories distribution\n",
    "print(\"Income Category Distribution:\")\n",
    "print(df_processed['Income_Category'].value_counts().sort_index())\n",
    "print(\"\\nPercentage:\")\n",
    "print((df_processed['Income_Category'].value_counts(normalize=True) * 100).sort_index().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Spending Categories distribution\n",
    "print(\"Spending Category Distribution:\")\n",
    "print(df_processed['Spending_Category'].value_counts().sort_index())\n",
    "print(\"\\nPercentage:\")\n",
    "print((df_processed['Spending_Category'].value_counts(normalize=True) * 100).sort_index().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Gender encoding\n",
    "print(\"Gender Encoding Verification:\")\n",
    "print(df_processed[['Gender', 'Gender_Encoded']].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Preprocessing Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive preprocessing report\n",
    "report = generate_preprocessing_report(df_original, df_processed)\n",
    "\n",
    "print(\"Preprocessing Report:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Original Shape: {report['Original_Shape']}\")\n",
    "print(f\"Processed Shape: {report['Processed_Shape']}\")\n",
    "print(f\"Rows Removed: {report['Rows_Removed']}\")\n",
    "print(f\"Features Added: {report['Features_Added']}\")\n",
    "print(f\"\\nNew Features: {report['New_Features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "processed_data_path = '../data/processed/mall_customers_processed.csv'\n",
    "save_processed_data(df_processed, processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessing report to file\n",
    "report_path = '../reports/results/preprocessing_report.txt'\n",
    "\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"DATA PREPROCESSING REPORT\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"1. OVERVIEW\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(f\"Original Shape: {report['Original_Shape']}\\n\")\n",
    "    f.write(f\"Processed Shape: {report['Processed_Shape']}\\n\")\n",
    "    f.write(f\"Rows Removed: {report['Rows_Removed']}\\n\")\n",
    "    f.write(f\"Features Added: {report['Features_Added']}\\n\\n\")\n",
    "    \n",
    "    f.write(\"2. PREPROCESSING STEPS\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(\"- Checked for missing values: None found\\n\")\n",
    "    f.write(\"- Removed duplicate rows: 0 duplicates found\\n\")\n",
    "    f.write(\"- Outlier handling: Kept all outliers (valid customer segments)\\n\")\n",
    "    f.write(\"- Feature engineering: Created derived categorical features\\n\\n\")\n",
    "    \n",
    "    f.write(\"3. NEW FEATURES CREATED\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    for feature in report['New_Features']:\n",
    "        f.write(f\"  - {feature}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"4. FEATURE DESCRIPTIONS\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(\"Age_Group: Categorical age ranges\\n\")\n",
    "    f.write(\"  - Young (18-25)\\n\")\n",
    "    f.write(\"  - Adult (26-35)\\n\")\n",
    "    f.write(\"  - Middle-Aged (36-50)\\n\")\n",
    "    f.write(\"  - Senior (50+)\\n\\n\")\n",
    "    \n",
    "    f.write(\"Income_Category: Annual income ranges\\n\")\n",
    "    f.write(\"  - Low Income (<40k)\\n\")\n",
    "    f.write(\"  - Medium Income (40-70k)\\n\")\n",
    "    f.write(\"  - High Income (70-100k)\\n\")\n",
    "    f.write(\"  - Very High Income (>100k)\\n\\n\")\n",
    "    \n",
    "    f.write(\"Spending_Category: Spending score ranges\\n\")\n",
    "    f.write(\"  - Low Spender (1-35)\\n\")\n",
    "    f.write(\"  - Medium Spender (36-65)\\n\")\n",
    "    f.write(\"  - High Spender (66-100)\\n\\n\")\n",
    "    \n",
    "    f.write(\"Gender_Encoded: Numerical encoding of gender\\n\")\n",
    "    f.write(\"  - Male = 1\\n\")\n",
    "    f.write(\"  - Female = 0\\n\\n\")\n",
    "    \n",
    "    f.write(\"5. OUTLIER ANALYSIS\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    for feature, stats in outlier_summary.items():\n",
    "        f.write(f\"\\n{feature}:\\n\")\n",
    "        f.write(f\"  Lower Bound: {stats['lower_bound']:.2f}\\n\")\n",
    "        f.write(f\"  Upper Bound: {stats['upper_bound']:.2f}\\n\")\n",
    "        f.write(f\"  Outlier Count: {stats['outlier_count']}\\n\")\n",
    "        f.write(f\"  Outlier Percentage: {stats['outlier_percentage']:.2f}%\\n\")\n",
    "    \n",
    "    f.write(\"\\n6. DATA QUALITY DECISIONS\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(\"Outliers: KEPT - They represent valid customer segments\\n\")\n",
    "    f.write(\"Duplicates: REMOVED - Ensured data uniqueness\\n\")\n",
    "    f.write(\"Missing Values: N/A - No missing values found\\n\")\n",
    "\n",
    "print(f\"\\nPreprocessing report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary of Transformations\n",
    "\n",
    "Run all cells above and document your findings here:\n",
    "\n",
    "### Data Cleaning:\n",
    "- Missing Values: [To be filled after running]\n",
    "- Duplicates Removed: [To be filled after running]\n",
    "- Outliers: Kept (represent valid customer segments)\n",
    "\n",
    "### Feature Engineering:\n",
    "- Created Age_Group: 4 categories based on age ranges\n",
    "- Created Income_Category: 4 categories based on income levels\n",
    "- Created Spending_Category: 3 categories based on spending scores\n",
    "- Created Gender_Encoded: Binary encoding for machine learning\n",
    "\n",
    "### Final Dataset:\n",
    "- Total Records: [To be filled after running]\n",
    "- Total Features: [To be filled after running]\n",
    "- Ready for EDA and Machine Learning\n",
    "\n",
    "### Next Steps:\n",
    "1. Proceed to exploratory data analysis with visualizations\n",
    "2. Use processed data for correlation analysis\n",
    "3. Apply machine learning models on clean data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
