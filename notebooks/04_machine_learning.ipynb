{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Customer Segmentation\n",
    "\n",
    "**Author:** Aleksandre Chakhvashvili\n",
    "**Purpose:** Implement K-Means clustering and classification models for customer segmentation\n",
    "\n",
    "## Objectives\n",
    "- Implement K-Means clustering to segment customers\n",
    "- Determine optimal number of clusters using Elbow method and Silhouette score\n",
    "- Visualize and analyze customer segments\n",
    "- Build classification models to predict customer segments\n",
    "- Compare model performance\n",
    "\n",
    "## Models Implemented\n",
    "1. K-Means Clustering (Unsupervised)\n",
    "2. Logistic Regression (Supervised)\n",
    "3. Decision Tree Classifier (Supervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import custom ML functions\n",
    "from models import (\n",
    "    prepare_clustering_features,\n",
    "    find_optimal_clusters_elbow,\n",
    "    calculate_silhouette_scores,\n",
    "    plot_elbow_curve,\n",
    "    plot_silhouette_scores,\n",
    "    train_kmeans,\n",
    "    visualize_clusters_2d,\n",
    "    analyze_clusters,\n",
    "    describe_clusters,\n",
    "    prepare_classification_data,\n",
    "    train_logistic_regression,\n",
    "    train_decision_tree,\n",
    "    evaluate_classifier,\n",
    "    plot_confusion_matrix,\n",
    "    compare_models\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "data_path = '../data/processed/mall_customers_processed.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Part 1: K-Means Clustering\n",
    "\n",
    "### 2.1 Feature Selection and Preparation\n",
    "\n",
    "For customer segmentation, we will use:\n",
    "- Annual Income (k$)\n",
    "- Spending Score (1-100)\n",
    "\n",
    "These features are most relevant for identifying distinct customer segments based on purchasing power and spending behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for clustering\n",
    "clustering_features = ['Annual Income (k$)', 'Spending Score (1-100)']\n",
    "\n",
    "print(\"Features selected for clustering:\")\n",
    "print(clustering_features)\n",
    "\n",
    "# Display feature statistics\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(df[clustering_features].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and scale features\n",
    "X_scaled, scaler = prepare_clustering_features(df, clustering_features)\n",
    "\n",
    "print(\"\\nScaled features:\")\n",
    "print(X_scaled.head())\n",
    "print(f\"\\nScaled data shape: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Determining Optimal Number of Clusters\n",
    "\n",
    "We will use two methods to determine the optimal number of clusters:\n",
    "1. Elbow Method - plots WCSS (Within-Cluster Sum of Squares)\n",
    "2. Silhouette Score - measures cluster quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate inertias for Elbow method\n",
    "print(\"Calculating WCSS for different values of k...\")\n",
    "inertias = find_optimal_clusters_elbow(X_scaled, max_k=10)\n",
    "\n",
    "print(\"\\nWCSS values:\")\n",
    "for k, inertia in inertias.items():\n",
    "    print(f\"k={k}: {inertia:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Elbow curve\n",
    "plot_elbow_curve(\n",
    "    inertias,\n",
    "    save_path='../reports/figures/20_elbow_curve.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Silhouette scores\n",
    "print(\"Calculating Silhouette scores for different values of k...\")\n",
    "silhouette_scores = calculate_silhouette_scores(X_scaled, max_k=10)\n",
    "\n",
    "print(\"\\nSilhouette scores:\")\n",
    "for k, score in silhouette_scores.items():\n",
    "    print(f\"k={k}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Silhouette scores\n",
    "plot_silhouette_scores(\n",
    "    silhouette_scores,\n",
    "    save_path='../reports/figures/21_silhouette_scores.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Optimal Cluster Selection\n",
    "\n",
    "Based on the Elbow curve and Silhouette scores, determine the optimal number of clusters.\n",
    "Common choices are between 3-5 clusters for customer segmentation.\n",
    "\n",
    "After examining the plots, select the optimal k value below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimal number of clusters based on analysis\n",
    "# Typically k=5 works well for this dataset based on elbow and silhouette analysis\n",
    "optimal_k = 5\n",
    "\n",
    "print(f\"Optimal number of clusters selected: {optimal_k}\")\n",
    "print(f\"WCSS for k={optimal_k}: {inertias[optimal_k]:.2f}\")\n",
    "print(f\"Silhouette score for k={optimal_k}: {silhouette_scores[optimal_k]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Train K-Means Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-Means clustering model\n",
    "kmeans_model, cluster_labels = train_kmeans(X_scaled, n_clusters=optimal_k, random_state=42)\n",
    "\n",
    "# Add cluster labels to original dataframe\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(df['Cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Visualize Customer Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters in 2D space\n",
    "visualize_clusters_2d(\n",
    "    df,\n",
    "    cluster_labels,\n",
    "    'Annual Income (k$)',\n",
    "    'Spending Score (1-100)',\n",
    "    title='Customer Segments - K-Means Clustering',\n",
    "    save_path='../reports/figures/22_customer_segments.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Analyze Cluster Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "cluster_analysis = analyze_clusters(df, cluster_labels, clustering_features)\n",
    "\n",
    "print(\"Cluster Analysis Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(cluster_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster descriptions\n",
    "cluster_descriptions = describe_clusters(df, cluster_labels)\n",
    "\n",
    "print(\"\\nCluster Descriptions:\")\n",
    "print(\"=\" * 80)\n",
    "for cluster_id, description in cluster_descriptions.items():\n",
    "    print(f\"Cluster {cluster_id}: {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional cluster analysis - demographic breakdown\n",
    "print(\"\\nCluster Demographics:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for cluster in sorted(df['Cluster'].unique()):\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    \n",
    "    print(f\"\\nCluster {cluster}: {cluster_descriptions[cluster]}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Size: {len(cluster_data)} customers ({len(cluster_data)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Average Age: {cluster_data['Age'].mean():.1f} years\")\n",
    "    print(f\"Average Income: ${cluster_data['Annual Income (k$)'].mean():.1f}k\")\n",
    "    print(f\"Average Spending Score: {cluster_data['Spending Score (1-100)'].mean():.1f}\")\n",
    "    print(f\"Gender Distribution: {cluster_data['Gender'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Part 2: Classification Models\n",
    "\n",
    "### 3.1 Prepare Data for Classification\n",
    "\n",
    "Now we will build classification models to predict customer cluster membership.\n",
    "This allows us to classify new customers into segments.\n",
    "\n",
    "Features used:\n",
    "- Age\n",
    "- Annual Income (k$)\n",
    "- Spending Score (1-100)\n",
    "- Gender_Encoded\n",
    "\n",
    "Target: Cluster label from K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for classification\n",
    "classification_features = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)', 'Gender_Encoded']\n",
    "target = 'Cluster'\n",
    "\n",
    "print(\"Classification Features:\")\n",
    "print(classification_features)\n",
    "print(f\"\\nTarget: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = prepare_classification_data(\n",
    "    df,\n",
    "    classification_features,\n",
    "    target,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "lr_model = train_logistic_regression(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Logistic Regression\n",
    "lr_results = evaluate_classifier(lr_model, X_test, y_test, model_name=\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for Logistic Regression\n",
    "plot_confusion_matrix(\n",
    "    lr_results['confusion_matrix'],\n",
    "    'Logistic Regression',\n",
    "    save_path='../reports/figures/23_confusion_matrix_lr.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model 2: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree model\n",
    "dt_model = train_decision_tree(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Decision Tree\n",
    "dt_results = evaluate_classifier(dt_model, X_test, y_test, model_name=\"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for Decision Tree\n",
    "plot_confusion_matrix(\n",
    "    dt_results['confusion_matrix'],\n",
    "    'Decision Tree',\n",
    "    save_path='../reports/figures/24_confusion_matrix_dt.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "model_results = {\n",
    "    'Logistic Regression': lr_results,\n",
    "    'Decision Tree': dt_results\n",
    "}\n",
    "\n",
    "comparison_table = compare_models(model_results)\n",
    "\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_table)\n",
    "\n",
    "# Identify best model\n",
    "best_model_idx = comparison_table['Accuracy'].idxmax()\n",
    "best_model_name = comparison_table.loc[best_model_idx, 'Model']\n",
    "best_accuracy = comparison_table.loc[best_model_idx, 'Accuracy']\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "lr_values = [lr_results['accuracy'], lr_results['precision'], lr_results['recall']]\n",
    "dt_values = [dt_results['accuracy'], dt_results['precision'], dt_results['recall']]\n",
    "\n",
    "plt.bar(x - width/2, lr_values, width, label='Logistic Regression', color='steelblue')\n",
    "plt.bar(x + width/2, dt_values, width, label='Decision Tree', color='orange')\n",
    "\n",
    "plt.xlabel('Metrics', fontsize=12)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (lr_val, dt_val) in enumerate(zip(lr_values, dt_values)):\n",
    "    plt.text(i - width/2, lr_val + 0.02, f'{lr_val:.3f}', ha='center', fontsize=9)\n",
    "    plt.text(i + width/2, dt_val + 0.02, f'{dt_val:.3f}', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/25_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Model comparison chart saved to: ../reports/figures/25_model_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data with cluster assignments\n",
    "output_path = '../data/processed/mall_customers_with_clusters.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Data with cluster assignments saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive ML report\n",
    "report_path = '../reports/results/ml_results_report.txt'\n",
    "\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"MACHINE LEARNING RESULTS REPORT\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"1. K-MEANS CLUSTERING\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(f\"Features Used: {', '.join(clustering_features)}\\n\")\n",
    "    f.write(f\"Optimal Number of Clusters: {optimal_k}\\n\")\n",
    "    f.write(f\"Silhouette Score: {silhouette_scores[optimal_k]:.4f}\\n\")\n",
    "    f.write(f\"WCSS (Inertia): {inertias[optimal_k]:.2f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Cluster Descriptions:\\n\")\n",
    "    for cluster_id, description in cluster_descriptions.items():\n",
    "        f.write(f\"  Cluster {cluster_id}: {description}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"Cluster Statistics:\\n\")\n",
    "    f.write(cluster_analysis.to_string())\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"2. CLASSIFICATION MODELS\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(f\"Features Used: {', '.join(classification_features)}\\n\")\n",
    "    f.write(f\"Target Variable: Cluster labels from K-Means\\n\")\n",
    "    f.write(f\"Train/Test Split: 80/20\\n\\n\")\n",
    "    \n",
    "    f.write(\"Model Performance Comparison:\\n\")\n",
    "    f.write(comparison_table.to_string(index=False))\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Best Model: {best_model_name}\\n\")\n",
    "    f.write(f\"Best Accuracy: {best_accuracy:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"3. DETAILED EVALUATION METRICS\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    \n",
    "    f.write(\"\\nLogistic Regression:\\n\")\n",
    "    f.write(f\"  Accuracy: {lr_results['accuracy']:.4f}\\n\")\n",
    "    f.write(f\"  Precision: {lr_results['precision']:.4f}\\n\")\n",
    "    f.write(f\"  Recall: {lr_results['recall']:.4f}\\n\")\n",
    "    f.write(f\"  Confusion Matrix:\\n{lr_results['confusion_matrix']}\\n\")\n",
    "    \n",
    "    f.write(\"\\nDecision Tree:\\n\")\n",
    "    f.write(f\"  Accuracy: {dt_results['accuracy']:.4f}\\n\")\n",
    "    f.write(f\"  Precision: {dt_results['precision']:.4f}\\n\")\n",
    "    f.write(f\"  Recall: {dt_results['recall']:.4f}\\n\")\n",
    "    f.write(f\"  Confusion Matrix:\\n{dt_results['confusion_matrix']}\\n\")\n",
    "\n",
    "print(f\"ML results report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Insights\n",
    "\n",
    "Run all cells above and document your findings here:\n",
    "\n",
    "### K-Means Clustering Results:\n",
    "- Optimal number of clusters: [To be filled after running]\n",
    "- Silhouette score: [To be filled after running]\n",
    "- Cluster characteristics: [To be filled after running]\n",
    "\n",
    "### Customer Segments Identified:\n",
    "1. [To be filled after running]\n",
    "2. [To be filled after running]\n",
    "3. [To be filled after running]\n",
    "4. [To be filled after running]\n",
    "5. [To be filled after running]\n",
    "\n",
    "### Classification Model Performance:\n",
    "- Logistic Regression Accuracy: [To be filled after running]\n",
    "- Decision Tree Accuracy: [To be filled after running]\n",
    "- Best performing model: [To be filled after running]\n",
    "\n",
    "### Business Recommendations:\n",
    "Based on the customer segments identified:\n",
    "1. [To be filled after running]\n",
    "2. [To be filled after running]\n",
    "3. [To be filled after running]\n",
    "\n",
    "### Model Selection Justification:\n",
    "- [To be filled after running - explain why one model performed better]\n",
    "- [Discuss trade-offs between models]\n",
    "\n",
    "### Next Steps:\n",
    "1. Update README.md with final results\n",
    "2. Prepare presentation materials\n",
    "3. Deploy model for new customer classification (optional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
