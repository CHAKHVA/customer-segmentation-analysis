{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "**Author:** Nino Gagnidze\n",
    "**Purpose:** Initial exploration and quality assessment of the Mall Customers dataset\n",
    "\n",
    "## Objectives\n",
    "- Load and inspect the raw dataset\n",
    "- Understand data structure and types\n",
    "- Identify data quality issues (missing values, duplicates, outliers)\n",
    "- Generate initial statistical summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '../data/raw/mall_customers.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 10 rows of the dataset:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last few rows\n",
    "print(\"Last 5 rows of the dataset:\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset information\n",
    "print(\"Dataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names and data types\n",
    "print(\"Column Names and Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Count:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nMissing Values Percentage:\")\n",
    "print((df.isnull().sum() / len(df) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate records\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"\\nDuplicate rows:\")\n",
    "    print(df[df.duplicated(keep=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate CustomerIDs\n",
    "duplicate_ids = df['CustomerID'].duplicated().sum()\n",
    "print(f\"Number of duplicate CustomerIDs: {duplicate_ids}\")\n",
    "\n",
    "if duplicate_ids > 0:\n",
    "    print(\"\\nDuplicate CustomerIDs:\")\n",
    "    print(df[df['CustomerID'].duplicated(keep=False)].sort_values('CustomerID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics for numerical features\n",
    "print(\"Descriptive Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional statistics\n",
    "print(\"Additional Statistics:\")\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'Mean': df[numerical_cols].mean(),\n",
    "    'Median': df[numerical_cols].median(),\n",
    "    'Mode': df[numerical_cols].mode().iloc[0],\n",
    "    'Std': df[numerical_cols].std(),\n",
    "    'Variance': df[numerical_cols].var(),\n",
    "    'Range': df[numerical_cols].max() - df[numerical_cols].min(),\n",
    "    'IQR': df[numerical_cols].quantile(0.75) - df[numerical_cols].quantile(0.25)\n",
    "})\n",
    "\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Gender distribution\n",
    "print(\"Gender Distribution:\")\n",
    "print(df['Gender'].value_counts())\n",
    "print(\"\\nGender Percentage:\")\n",
    "print(df['Gender'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique values in categorical columns\n",
    "print(\"Unique values in Gender column:\")\n",
    "print(df['Gender'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outlier Detection (Initial Assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect outliers using IQR method\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"\n",
    "    Detect outliers using the Interquartile Range (IQR) method.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        Input dataframe\n",
    "    column : str\n",
    "        Column name to check for outliers\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with outlier information\n",
    "    \"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    \n",
    "    return {\n",
    "        'column': column,\n",
    "        'Q1': Q1,\n",
    "        'Q3': Q3,\n",
    "        'IQR': IQR,\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound,\n",
    "        'outlier_count': len(outliers),\n",
    "        'outlier_percentage': (len(outliers) / len(data)) * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers for numerical columns\n",
    "numerical_features = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n",
    "\n",
    "print(\"Outlier Detection Summary (IQR Method):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for col in numerical_features:\n",
    "    outlier_info = detect_outliers_iqr(df, col)\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Q1: {outlier_info['Q1']:.2f}\")\n",
    "    print(f\"  Q3: {outlier_info['Q3']:.2f}\")\n",
    "    print(f\"  IQR: {outlier_info['IQR']:.2f}\")\n",
    "    print(f\"  Lower Bound: {outlier_info['lower_bound']:.2f}\")\n",
    "    print(f\"  Upper Bound: {outlier_info['upper_bound']:.2f}\")\n",
    "    print(f\"  Outlier Count: {outlier_info['outlier_count']}\")\n",
    "    print(f\"  Outlier Percentage: {outlier_info['outlier_percentage']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Range Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if values are within expected ranges\n",
    "print(\"Data Range Validation:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Age validation (should be positive)\n",
    "invalid_age = df[df['Age'] <= 0]\n",
    "print(f\"\\nInvalid Age values (<=0): {len(invalid_age)}\")\n",
    "\n",
    "# Income validation (should be positive)\n",
    "invalid_income = df[df['Annual Income (k$)'] <= 0]\n",
    "print(f\"Invalid Annual Income values (<=0): {len(invalid_income)}\")\n",
    "\n",
    "# Spending Score validation (should be between 1-100)\n",
    "invalid_spending = df[(df['Spending Score (1-100)'] < 1) | (df['Spending Score (1-100)'] > 100)]\n",
    "print(f\"Invalid Spending Score values (not in 1-100 range): {len(invalid_spending)}\")\n",
    "\n",
    "# Gender validation\n",
    "valid_genders = ['Male', 'Female']\n",
    "invalid_gender = df[~df['Gender'].isin(valid_genders)]\n",
    "print(f\"Invalid Gender values: {len(invalid_gender)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Initial Insights Summary\n",
    "\n",
    "Run all cells above and document your findings here:\n",
    "\n",
    "### Data Quality Status:\n",
    "- Missing Values: [To be filled after running cells]\n",
    "- Duplicate Records: [To be filled after running cells]\n",
    "- Data Types: [To be filled after running cells]\n",
    "\n",
    "### Key Observations:\n",
    "- Total Records: [To be filled after running cells]\n",
    "- Features: [To be filled after running cells]\n",
    "- Gender Distribution: [To be filled after running cells]\n",
    "\n",
    "### Data Quality Issues Identified:\n",
    "1. [To be filled after running cells]\n",
    "2. [To be filled after running cells]\n",
    "\n",
    "### Next Steps:\n",
    "1. Address identified data quality issues in preprocessing notebook\n",
    "2. Decide on outlier handling strategy\n",
    "3. Plan feature engineering approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Exploration Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data quality report\n",
    "quality_report = {\n",
    "    'Total Records': len(df),\n",
    "    'Total Features': len(df.columns),\n",
    "    'Missing Values': df.isnull().sum().sum(),\n",
    "    'Duplicate Rows': df.duplicated().sum(),\n",
    "    'Duplicate CustomerIDs': df['CustomerID'].duplicated().sum(),\n",
    "    'Gender Distribution': df['Gender'].value_counts().to_dict(),\n",
    "    'Age Range': f\"{df['Age'].min()} - {df['Age'].max()}\",\n",
    "    'Income Range': f\"{df['Annual Income (k$)'].min()} - {df['Annual Income (k$)'].max()}\",\n",
    "    'Spending Score Range': f\"{df['Spending Score (1-100)'].min()} - {df['Spending Score (1-100)'].max()}\"\n",
    "}\n",
    "\n",
    "print(\"Data Quality Report:\")\n",
    "for key, value in quality_report.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save basic statistics to file for reference\n",
    "stats_output_path = '../reports/results/data_exploration_stats.txt'\n",
    "\n",
    "with open(stats_output_path, 'w') as f:\n",
    "    f.write(\"DATA EXPLORATION SUMMARY\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    f.write(f\"Dataset Shape: {df.shape}\\n\")\n",
    "    f.write(f\"Total Records: {len(df)}\\n\")\n",
    "    f.write(f\"Total Features: {len(df.columns)}\\n\\n\")\n",
    "    f.write(\"Columns: \" + \", \".join(df.columns.tolist()) + \"\\n\\n\")\n",
    "    f.write(\"Data Types:\\n\")\n",
    "    f.write(df.dtypes.to_string() + \"\\n\\n\")\n",
    "    f.write(\"Missing Values:\\n\")\n",
    "    f.write(df.isnull().sum().to_string() + \"\\n\\n\")\n",
    "    f.write(\"Descriptive Statistics:\\n\")\n",
    "    f.write(df.describe().to_string() + \"\\n\")\n",
    "\n",
    "print(f\"Exploration summary saved to {stats_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
